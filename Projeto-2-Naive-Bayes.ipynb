{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2 - Classificador Automático de Sentimento\n",
    "\n",
    "## Integrantes: Lucas Leal Vale, Matheus Augusto Soares, Rafael Almada\n",
    "\n",
    "Você foi contratado por uma empresa parar analisar como os clientes estão reagindo a um determinado produto no Twitter. A empresa deseja que você crie um programa que irá analisar as mensagens disponíveis e classificará como \"relevante\" ou \"irrelevante\". Com isso ela deseja que mensagens negativas, que denigrem o nome do produto, ou que mereçam destaque, disparem um foco de atenção da área de marketing.<br /><br />\n",
    "Como aluno de Ciência dos Dados, você lembrou do Teorema de Bayes, mais especificamente do Classificador Naive-Bayes, que é largamente utilizado em filtros anti-spam de e-mails. O classificador permite calcular qual a probabilidade de uma mensagem ser relevante dadas as palavras em seu conteúdo.<br /><br />\n",
    "Para realizar o MVP (*minimum viable product*) do projeto, você precisa implementar uma versão do classificador que \"aprende\" o que é relevante com uma base de treinamento e compara a performance dos resultados com uma base de testes.<br /><br />\n",
    "Após validado, o seu protótipo poderá também capturar e classificar automaticamente as mensagens da plataforma.\n",
    "\n",
    "## Informações do Projeto\n",
    "\n",
    "Prazo: 19/Set até às 23:59.<br />\n",
    "Grupo: 2 ou 3 pessoas - grupos com 3 pessoas terá uma rubrica diferenciada.<br /><br />\n",
    "Entregáveis via GitHub: \n",
    "* Arquivo notebook com o código do classificador, seguindo as orientações abaixo.\n",
    "* Arquivo Excel com as bases de treinamento e teste totalmente classificado.\n",
    "\n",
    "**NÃO gravar a key do professor no arquivo**\n",
    "\n",
    "\n",
    "### Entrega Intermediária: Check 1 - APS 2\n",
    "\n",
    "Até o dia 10/Set às 23:59, xlsx deve estar no Github com as seguintes evidências: \n",
    "\n",
    "  * Produto escolhido.\n",
    "  * Arquivo Excel contendo a base de treinamento e a base de testes já classificadas.\n",
    "\n",
    "Sugestão de leitura:<br />\n",
    "https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "## Introdução\n",
    "\n",
    "Vivemos na era da informação, tudo pode ser usado para o bem ou para o mal, desde o que o indíviduo tá sentido, seja relacionado a uma empresa, produto ou até por alguma questão qualquer, o lugar por onde as pessoas passam, o que curtem em uma rede social, tudo pode ser usado para entender o comortamento social de um nicho específico da sociedade ou até traçar uma média geral para a nação. Com o avanço do conhecimento e do desenvolvimento do poderio da tecnologia, o ser humano percebeu que não precisa depender apenas de si, até por que ele mesmo é muito falho, mas podemos nos utilizar de máquinas não só para registrar, mas para pensar. Assim nasceu o conhecido 'Machine Learning', área da computação que visa programar um computador para aprender com o humano e por meio de probabilidades realizar o mesmo trabalho.\n",
    "\n",
    "Neste trabalho, utilizamos de uma técnica muito simples de Machine Learning, chamada \"Naive Bayes\" (traduzido literalmente para Bayes ingênuo). O nome faz uma homenagem a Thomas Bayes (1701 – 1761), matemático inglês que estudou como calcular a distribuição para o parâmetro de probabilidade de uma distribuição binomial e acabou por chegar na famosa equação de probabilidades, a equação de Bayes:\n",
    "\n",
    "### $$P(A | B) = \\frac{P(B | A)·P(A)}{P(B)}$$\n",
    "\n",
    "Contudo, nosso objetivo é analisar qual a reputação da empresa 'Riot Games', com base no seu público no twitter, para isso recolhemos um dataframe de 300 tweets de treinamento para que o algoritmo desenvolvido possa tomar como base e 700 tweets de teste para verificarmos o quão preciso ele é. A importância de um projeto como esse para uma empresa seria a informação estatística de como ela é vista pelo público em determinada rede social para se embasar em decisões futuras de investimentos, marketing, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Parte I - Adquirindo a Base de Dados\n",
    "\n",
    "Acessar o notebook **Projeto-2-Planilha** para realizar a coleta dos dados. O grupo deve classificar os dados coletados manualmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Primeiros passos...\n",
    "\n",
    "O primeiro passo para criar o classificador Naive-Bayes é importar nosso dataframe, para isso devemos escolher qual rede social iremos trabalhar e no caso será o Twitter. A partir de uma api, conseguimos acesso para extrair um dataframe em excel com diversos 'Tweets' (postagens desta rede em específico). Também devemos importar as bibliotecas que utilizaremos como pandas e matplotlib. O tema escolhido para o projeto é Hearthstone, um jogo de cartas online, um dos grandes eSports da atualidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_excel('tweets_rappi.xlsx','Treinamento',sep=',')\n",
    "dfTeste=pd.read_excel('tweets_rappi.xlsx', 'Teste',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, devemos \"limpar\" o dataframe, ou seja, remover parênteses, colchetes, etc. Estes caracteres interferem na análise das palavras e devem necessariamente ser removidos dos nossos tweets. Também iremos transformar os tweets em listas de strings, a separação de cada string se dá pelo espaço entre as palavras após a limpeza das mesmas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lista1=['  ','   ',':','(',')','`','[',']','.','/','\" ',\"'\"]\n",
    "lista2=[' ',' ',' ',' ',' ',' ',' ',' ',' ',' ',' ',' ']\n",
    "for i in range(len(lista1)):\n",
    "    df['Treinamento']=df.Treinamento.str.replace(lista1[i], lista2[i])\n",
    "    dfTeste['Teste']=dfTeste.Teste.str.replace(lista1[i], lista2[i])\n",
    "df['Treinamento']=df.Treinamento.str.lower()\n",
    "dfTeste['Teste']=dfTeste.Teste.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [ganhe, r$100, em, frete, no, seus, primeiros,...\n",
       "1    [@viniciusprimo_, @ifood, @rappibrasil, btw, a...\n",
       "2    [rappi, fez, o, meu, dia, me, dando, 30, reais...\n",
       "3    [todo, mundo, deve, achar, que, morar, sozinha...\n",
       "4    [um, timing, perfeito, @mizanzika, @luide, tiv...\n",
       "Name: Treinamento, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Treinamento']=df['Treinamento'].str.split()\n",
    "dfTeste['Teste']=dfTeste['Teste'].str.split()\n",
    "df['Treinamento'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Parte II - Montando o Classificador Naive-Bayes\n",
    "\n",
    "Com a base de treinamento montada, comece a desenvolver o classificador. Não se esqueça de implementar o Laplace Smoothing (https://en.wikipedia.org/wiki/Laplace_smoothing).\n",
    "\n",
    "Opcionalmente: \n",
    "* Limpar as mensagens removendo os caracteres: enter, :, \", ', (, ), etc. Não remover emojis.<br />\n",
    "* Corrigir separação de espaços entre palavras e/ou emojis.\n",
    "* Propor outras limpezas/transformações que não afetem a qualidade da informação.\n",
    "\n",
    "Escreva o seu código abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### O que precisamos?\n",
    "Agora chegou a hora de estruturar nossa função que calculará o nosso Bayes. Para isso precisamos das seguintes probabilidades:\n",
    "\n",
    "<br>Probabilidade da palavra ser Irrelevante dentro do espaço amostral de todas as palavras.</br>\n",
    "<br>Probabilidade da palavra ser Ruim dentro do espaço amostral de todas as palavras.</br>\n",
    "<br>Probabilidade da palavra ser Neutra dentro do espaço amostral de todas as palavras.</br>\n",
    "<br>Probabilidade da palavra ser Boa dentro do espaço amostral de todas as palavras.</br>\n",
    "\n",
    "Além disso, precisaremos das probabilidades condicionais individuais das palavras dado sua categoria (bom, ruim, neutro ou irrelevante). Para esse cálculo precisamos ver quantas vezes cada palavra aparece na categoria em específico dividido pelo número de palavras totais classificadas nessa categoria. Porém nem tudo são flores, existe a possibilidade de no teste de tweets novos, aparecerem palavras nunca antes vistas pelo nosso algoritmo, mas existe uma solução graças a La Place! A técnica que utilizaremos se chama \"Laplace smoothing\" e ela se trata de, na probabilidade condicional da palavra dado a categoria, adicionar 1 ao numerador e adicionar o número de palavras totais no treinamento sem repetições ao denominador. Sempre que aparecer uma palavra nova, devemos adicionar isso e assim ele não alterará muito a classificação do tweet, dando uma probabilidade de acerto maior ao classificador.\n",
    "\n",
    "Então vamos ao código...\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfLen=len(df)\n",
    "\n",
    "dfBom=df[df['Classificação']==3]\n",
    "dfBomLen=len(dfBom)\n",
    "\n",
    "dfNeutro=df[df['Classificação']==2]\n",
    "dfNeutroLen=len(dfNeutro)\n",
    "\n",
    "dfRuim=df[df['Classificação']==1]\n",
    "dfRuimLen=len(dfRuim)\n",
    "\n",
    "dfIrre=df[df['Classificação']==0]\n",
    "dfIrreLen=len(dfIrre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Contagem de palavras dado sua categoria\n",
    "#Bom\n",
    "dfBomProb=dfBom[\"Treinamento\"].sum()\n",
    "dfBomProb=pd.Series(dfBomProb)\n",
    "dfBomProb=dfBomProb.value_counts()\n",
    "\n",
    "#Ruim\n",
    "dfRuimProb=dfRuim[\"Treinamento\"].sum()\n",
    "dfRuimProb=pd.Series(dfRuimProb)\n",
    "dfRuimProb=dfRuimProb.value_counts()\n",
    "\n",
    "#Irrelevante\n",
    "dfIrreProb=dfIrre[\"Treinamento\"].sum()\n",
    "dfIrreProb=pd.Series(dfIrreProb)\n",
    "dfIrreProb=dfIrreProb.value_counts()\n",
    "\n",
    "#Neutro\n",
    "dfNeutroProb=dfNeutro[\"Treinamento\"].sum()\n",
    "dfNeutroProb=pd.Series(dfNeutroProb)\n",
    "dfNeutroProb=dfNeutroProb.value_counts()\n",
    "\n",
    "#Total\n",
    "dfTotal=df.Treinamento.sum()\n",
    "dfTotal=pd.Series(dfTotal)\n",
    "dfTotal=dfTotal.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Número total de palavras no dataframe\n",
    "dfPalavras=df.Treinamento.sum()\n",
    "dfPalavras=pd.Series(dfPalavras)\n",
    "dfPalavras=len(dfPalavras)\n",
    "\n",
    "#Check de palavras\n",
    "check=df.Treinamento.sum()\n",
    "check=pd.Series(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Números totais de palavras em cada categoria, mas agora em variáveis\n",
    "#Bom\n",
    "BoasPalavras=dfBom[\"Treinamento\"].sum()\n",
    "BoasPalavras=pd.Series(BoasPalavras)\n",
    "BoasPalavras=len(BoasPalavras)\n",
    "\n",
    "#Ruim\n",
    "RuimPalavras=dfRuim[\"Treinamento\"].sum()\n",
    "RuimPalavras=pd.Series(RuimPalavras)\n",
    "RuimPalavras=len(RuimPalavras)\n",
    "\n",
    "#Irrelevante\n",
    "IrrePalavras=dfIrre[\"Treinamento\"].sum()\n",
    "IrrePalavras=pd.Series(IrrePalavras)\n",
    "IrrePalavras=len(IrrePalavras)\n",
    "\n",
    "#Neutro\n",
    "NeutroPalavras=dfNeutro[\"Treinamento\"].sum()\n",
    "NeutroPalavras=pd.Series(NeutroPalavras)\n",
    "NeutroPalavras=len(NeutroPalavras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A probablidade de ser Irrelevante é: 13.863 %\n",
      "A probablidade de ser Ruim é: 21.935 %\n",
      "A probablidade de ser Neutro é: 39.255 %\n",
      "A probablidade de ser Bom  é: 24.555 %\n"
     ]
    }
   ],
   "source": [
    "# Probabilidades base\n",
    "ProbBom=BoasPalavras/(dfPalavras)\n",
    "ProbRuim=RuimPalavras/(dfPalavras)\n",
    "ProbIrre=IrrePalavras/(dfPalavras)\n",
    "ProbNeutro=NeutroPalavras/(dfPalavras)\n",
    "\n",
    "print('A probablidade de ser Irrelevante é: {0:.3f} %'.format(ProbIrre*100))\n",
    "print('A probablidade de ser Ruim é: {0:.3f} %'.format(ProbRuim*100))\n",
    "print('A probablidade de ser Neutro é: {0:.3f} %'.format(ProbNeutro*100))\n",
    "print('A probablidade de ser Bom  é: {0:.3f} %'.format(ProbBom*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Técnica laplace 3 (74.66% de acerto no treinamento)\n",
    "g=[]\n",
    "for i in check:\n",
    "    if i not in g:\n",
    "        g.append(i)\n",
    "lala=len(g)\n",
    "dfBomProb2=(dfBomProb+1)/(BoasPalavras+lala)\n",
    "dfRuimProb2=(dfRuimProb+1)/(RuimPalavras+lala)\n",
    "dfIrreProb2=(dfIrreProb+1)/(IrrePalavras+lala)\n",
    "dfNeutroProb2=(dfNeutroProb+1)/(NeutroPalavras+lala)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resultado=[]\n",
    "def bayes(df,dfPalavras,lista):\n",
    "    laplace=(1/(lala))# obs da folha\n",
    "    for i in df: # for i in df.index:\n",
    "        c_bom=1\n",
    "        c_ruim=1\n",
    "        c_irre=1\n",
    "        c_neutro=1\n",
    "        for u in i:\n",
    "            #p=dfTotal[u]/len(dfTotal) #(Probabilidade da palavra no espaço amostral de todas as palavras)\n",
    "            if u not in dfBomProb2:\n",
    "                p_bom=laplace\n",
    "            else:\n",
    "                p_bom=dfBomProb2[u]\n",
    "            if u not in dfRuimProb2:\n",
    "                p_ruim=laplace\n",
    "            else:\n",
    "                p_ruim=dfRuimProb2[u]\n",
    "            if u not in dfIrreProb2:\n",
    "                p_irre=laplace\n",
    "            else:\n",
    "                p_irre=dfIrreProb2[u]\n",
    "            if u not in dfNeutroProb2:\n",
    "                p_neutro=laplace\n",
    "            else:\n",
    "                p_neutro=dfNeutroProb2[u]\n",
    "                \n",
    "            c_bom*=(p_bom)\n",
    "            c_ruim*=(p_ruim)\n",
    "            c_irre*=(p_irre)\n",
    "            c_neutro*=(p_neutro)\n",
    "        c_bom=c_bom*(ProbBom)\n",
    "        #print(\"c_bom:\",c_bom)\n",
    "        c_ruim=c_ruim*(ProbRuim)\n",
    "        #print(\"c_ruim:\",c_ruim)\n",
    "        c_irre=c_irre*(ProbIrre)\n",
    "        #print(\"c_irre:\",c_irre)\n",
    "        c_neutro=c_neutro*(ProbNeutro)\n",
    "\n",
    "        if c_bom>c_ruim and c_bom>c_irre and c_bom>c_neutro:\n",
    "            #Classifica como Bom (3)\n",
    "            lista.append(3)\n",
    "\n",
    "        elif c_ruim>c_bom and c_ruim>c_irre and c_ruim>c_neutro:\n",
    "            #Classifica como Ruim (1)\n",
    "            lista.append(1)\n",
    "        elif c_irre>c_bom and c_irre>c_ruim and c_irre>c_neutro:\n",
    "            #Classifica como irrelevante (0)\n",
    "            lista.append(0)\n",
    "        else:\n",
    "            #Classifica como neutro (2) \n",
    "            lista.append(2)\n",
    "    return lista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que nossa função Bayes está pronta, podemos testar ela com o nosso próprio treinamento. No caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=bayes(df[\"Treinamento\"],dfPalavras,resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "[2, 1, 3, 3, 0, 1, 3, 3, 3, 1, 2, 3, 2, 1, 2, 2, 1, 1, 1, 1, 1, 3, 1, 2, 2, 2, 3, 2, 3, 1, 3, 2, 2, 2, 0, 3, 2, 2, 3, 1, 1, 2, 3, 2, 2, 2, 1, 1, 3, 2, 1, 1, 2, 2, 1, 3, 3, 3, 1, 3, 3, 1, 3, 2, 3, 2, 3, 1, 1, 2, 1, 2, 1, 2, 0, 2, 2, 0, 3, 2, 3, 2, 2, 2, 1, 1, 3, 2, 3, 2, 2, 2, 2, 1, 2, 2, 2, 3, 3, 2, 1, 1, 1, 1, 2, 1, 3, 1, 0, 2, 3, 1, 3, 3, 1, 3, 1, 3, 2, 1, 3, 2, 3, 2, 2, 1, 2, 2, 1, 1, 3, 2, 2, 3, 2, 3, 1, 1, 1, 2, 0, 3, 3, 1, 2, 2, 2, 0, 3, 3, 2, 2, 2, 3, 3, 1, 1, 1, 1, 2, 0, 2, 1, 2, 1, 2, 1, 3, 3, 2, 2, 3, 2, 2, 3, 0, 2, 2, 2, 1, 1, 1, 3, 1, 3, 3, 3, 1, 2, 2, 1, 2, 3, 1, 1, 0, 2, 3, 2, 2, 2, 3, 0, 2, 3, 3, 3, 3, 3, 1, 1, 1, 3, 2, 3, 2, 2, 1, 3, 3, 1, 3, 3, 3, 2, 3, 0, 3, 1, 0, 2, 3, 3, 2, 1, 3, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 2, 3, 2, 2, 3, 2, 0, 0, 0, 2, 2, 1, 2, 3, 1, 1, 2, 1, 2, 1, 3, 2, 3, 2, 2, 3, 3, 1, 2, 1, 1, 0, 2, 2, 1, 2, 2, 0, 2, 1, 1, 3, 2, 2, 2, 3, 0, 2, 3, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(len(resultado))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Resultado\"]=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Classificação</th>\n",
       "      <th>Legenda</th>\n",
       "      <th>Resultado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ganhe, r$100, em, frete, no, seus, primeiros,...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0 - IRRELEVANTE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[@viniciusprimo_, @ifood, @rappibrasil, btw, a...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1 - RUIM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[rappi, fez, o, meu, dia, me, dando, 30, reais...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2 - NEUTRO</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[todo, mundo, deve, achar, que, morar, sozinha...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3 - BOM</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[um, timing, perfeito, @mizanzika, @luide, tiv...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Classificação  \\\n",
       "0  [ganhe, r$100, em, frete, no, seus, primeiros,...            2.0   \n",
       "1  [@viniciusprimo_, @ifood, @rappibrasil, btw, a...            2.0   \n",
       "2  [rappi, fez, o, meu, dia, me, dando, 30, reais...            3.0   \n",
       "3  [todo, mundo, deve, achar, que, morar, sozinha...            2.0   \n",
       "4  [um, timing, perfeito, @mizanzika, @luide, tiv...            2.0   \n",
       "\n",
       "           Legenda  Resultado  \n",
       "0  0 - IRRELEVANTE          2  \n",
       "1         1 - RUIM          1  \n",
       "2       2 - NEUTRO          3  \n",
       "3          3 - BOM          3  \n",
       "4              NaN          0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Resultado</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Classificação</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>77</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Resultado       0   1   2   3\n",
       "Classificação                \n",
       "0.0            17   6  19   8\n",
       "1.0             1  60   5   3\n",
       "2.0             1  10  77  13\n",
       "3.0             0   4  16  59"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx=pd.crosstab(df['Classificação'], df['Resultado'])\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxa de Acerto: 71.237 %\n"
     ]
    }
   ],
   "source": [
    "acerto=(xx[0][0]+xx[1][1]+xx[2][2]+xx[3][3])/(sum(xx[0])+sum(xx[1])+sum(xx[2])+sum(xx[3]))\n",
    "print(\"Taxa de Acerto: {:.3f} %\".format(acerto*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testando no treinamento:\n",
      "\n",
      "Taxa de Irrelevante Verdadeiro: 89.474 %\n",
      "Taxa de Irrelevante Falso: 10.526 %\n",
      "-------------------------\n",
      "Taxa de Ruim Verdadeiro: 7.500 %\n",
      "Taxa de Ruim Falso: 92.500 %\n",
      "-------------------------\n",
      "Taxa de Neutro Verdadeiro: 16.239 %\n",
      "Taxa de Neutro Falso: 83.761 %\n",
      "-------------------------\n",
      "Taxa de Bom Verdadeiro: 9.639 %\n",
      "Taxa de Bom Falso: 90.361 %\n",
      "-------------------------\n",
      "{'Irrelevante': [0.89473684210526316, 0.10526315789473684], 'Ruim': [0.074999999999999997, 0.92500000000000004], 'Neutro': [0.1623931623931624, 0.83760683760683763], 'Bom': [0.096385542168674704, 0.90361445783132532]}\n"
     ]
    }
   ],
   "source": [
    "def verifica(ct, categorias): #ct = Crosstab ; categoria = 'string' (ruim, bom, etc)\n",
    "    dicio={}\n",
    "    for i in categorias:\n",
    "        if i=='Irrelevante':\n",
    "            verdadeiro=(ct[0][0])/sum(ct[0])\n",
    "            falso=(sum(ct[0])-ct[0][0])/sum(ct[0])\n",
    "        elif i=='Ruim':\n",
    "            verdadeiro=(ct[1][0])/sum(ct[1])\n",
    "            falso=(sum(ct[1])-ct[1][0])/sum(ct[1])\n",
    "        elif i=='Neutro':\n",
    "            verdadeiro=(ct[2][0])/sum(ct[2])\n",
    "            falso=(sum(ct[2])-ct[2][0])/sum(ct[2])\n",
    "        elif i=='Bom':\n",
    "            verdadeiro=(ct[3][0])/sum(ct[3])\n",
    "            falso=(sum(ct[3])-ct[3][0])/sum(ct[3])\n",
    "        print('Taxa de {0} Verdadeiro: {1:.3f} %'.format(i,verdadeiro*100))\n",
    "        print('Taxa de {0} Falso: {1:.3f} %'.format(i,falso*100))\n",
    "        print('-'*25)\n",
    "        dicio[i]=[verdadeiro,falso]\n",
    "    return(dicio)\n",
    "cat=['Irrelevante','Ruim','Neutro','Bom']\n",
    "print('Testando no treinamento:\\n')\n",
    "ver=verifica(xx,cat)\n",
    "print(ver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Verificando a performance\n",
    "\n",
    "Agora você deve testar o seu Classificador com a base de Testes.<br /><br /> \n",
    "\n",
    "Você deve extrair as seguintes medidas:\n",
    "* Porcentagem de positivos falsos (marcados como relevante mas não são relevantes)\n",
    "* Porcentagem de positivos verdadeiros (marcado como relevante e são relevantes)\n",
    "* Porcentagem de negativos verdadeiros (marcado como não relevante e não são relevantes)\n",
    "* Porcentagem de negativos falsos (marcado como não relevante e são relevantes)\n",
    "\n",
    "Obrigatório para grupos de 3 alunos:\n",
    "* Criar categorias intermediárias de relevância baseado na diferença de probabilidades. Exemplo: muito relevante, relevante, neutro, irrelevante e muito irrelevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r=[]\n",
    "b=bayes(dfTeste['Teste'], dfPalavras,r)\n",
    "dfTeste['Resultado']=b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ct_teste=pd.crosstab(dfTeste['Classificação'],dfTeste['Resultado'])\n",
    "ct_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ver_teste=verifica(ct_teste,cat)\n",
    "ver_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acerto2=(ct_teste[0][0]+ct_teste[1][1]+ct_teste[2][2])/(sum(ct_teste[0])+sum(ct_teste[1])+sum(ct_teste[2]))\n",
    "print(\"Taxa de Acerto: {:.3f} %\".format(acerto*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Concluindo\n",
    "\n",
    "Escreva aqui a sua conclusão.<br /> \n",
    "Faça um comparativo qualitativo sobre as medidas obtidas.<br />\n",
    "Explique como são tratadas as mensagens com dupla negação e sarcasmo.<br />\n",
    "Proponha um plano de expansão. Por que eles devem continuar financiando o seu projeto?<br />\n",
    "\n",
    "Opcionalmente: \n",
    "* Discorrer por que não posso alimentar minha base de Treinamento automaticamente usando o próprio classificador, aplicado a novos tweets.\n",
    "* Propor diferentes cenários de uso para o classificador Naive-Bayes. Cenários sem intersecção com este projeto.\n",
    "* Sugerir e explicar melhorias reais no classificador com indicações concretas de como implementar (não é preciso codificar, mas indicar como fazer e material de pesquisa sobre o assunto).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "### Como podemos melhorar?\n",
    "\n",
    "Para melhor o nosso machine learning, uma coisa importante seria aumentar nossa base de treinamento e classifica-la com a maior proximidade com a realidade possível. Outro ponto seria aumentar uma categoria, para que assim tivessemos mais possibilidades de 'Sentimentos' atrelados a cada postagem, no caso seria Irrelevante, Ruim, Neutro, Bom e Muito Bom, o que poderia permitir uma análise mais profunda dos dados. Para melhorar a eficiência do código, poderiamos trabalhar com uma classe geral que recebe um dataframe classificado e retorna uma análise dos dados, além da classificação do Naive-Bayes. Poderíamos usar dicionários ao invés de listas pois otimizariam o tempo de execução do código. Outra coisa que podíamos implementar seria filtrar emojis e separa-los como strings para que assim eles fossem avaliados individualmente como se fossem palavras e trariam mais certeza ao código.\n",
    "\n",
    "Porém essas são algumas hipóteses que nosso grupo teve para otimizar este projeto em futuras iterações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
